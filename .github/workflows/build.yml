name: Automated Build and Test

on:
  push:
    branches:
      - "**"

jobs:
  build_and_test:
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 4
      matrix:
        python-version: [3.7]
    steps:
      - name: Clone git repo
        uses: actions/checkout@v1
      - name: Build Docker image
        run: |
          docker build -t dataops-project .
      - name: Compile DBT project
        env:
          SPARK_WAREHOUSE_DIR: /spark_warehouse
        run: >
          docker run --rm
          -v $(cwd):/projects/my-project
          -v $(cwd)/../spark/warehouse:/spark_warehouse
          -v $(cwd)/../spark/metastore:/var/lib/mysql
          -w /projects/my-project
          dataops-project
          dbt-spark compile
          --profiles-dir etc/dbt-config
      - name: Run DBT project
        env:
          SPARK_WAREHOUSE_DIR: /spark_warehouse
        run: >
          docker run --rm
          -v $(cwd):/projects/my-project
          -v $(cwd)/../spark/warehouse:/spark_warehouse
          -v $(cwd)/../spark/metastore:/var/lib/mysql
          -w /projects/my-project
          dataops-project
          dbt-spark run
          --profiles-dir etc/dbt-config
      - name: Check spark outputs
        run: |
          cd $(cwd)/../spark/warehouse
          ls -Rla
          du -a .
